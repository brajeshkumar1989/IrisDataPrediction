{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig():\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.irisdataprediction.constants import *\n",
    "from src.irisdataprediction.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH, schema_filepath=SCHEMA_FILE_PATH):\n",
    "        self.config= read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "        self.schema=read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])   \n",
    "\n",
    "    def get_data_transformation_config(self)->DataTransformationConfig:\n",
    "        config= self.config.data_transformation\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config= DataTransformationConfig(root_dir=config.root_dir, data_path=config.data_path)\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.irisdataprediction import logger\n",
    "from src.irisdataprediction.exception import IrisPredictionException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig, threshold=0):\n",
    "        self.config=config\n",
    "        self.threshold=threshold\n",
    "        self.dataset=pd.read_csv(self.config.data_path)\n",
    "        self.dataset_columns=self.dataset.columns\n",
    "        self.transformed_dataset=None\n",
    "\n",
    "\n",
    "    \n",
    "    def data_standardization(self):\n",
    "        num_pipeline=make_pipeline(SimpleImputer(strategy='median'),StandardScaler())\n",
    "        cat_pipeline=make_pipeline(SimpleImputer(strategy='most_frequent'), OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan))\n",
    "        preprocessing= make_column_transformer((num_pipeline, make_column_selector(dtype_include=np.number)),(cat_pipeline, make_column_selector(dtype_include=object)))\n",
    "\n",
    "        self.dataset= preprocessing.fit_transform(self.dataset)\n",
    "        self.transformed_dataset=pd.DataFrame(data=self.dataset,columns=self.dataset_columns, index=None)\n",
    "\n",
    "    def remove_correlated_columns(self):\n",
    "\n",
    "        col_corr=set() #set of the names of correlated columns\n",
    "        corr_matrix=self.transformed_dataset.select_dtypes(include=[np.number]).corr()\n",
    "        logger.info(f\"<<<<<< Data Transformation: correlation between different columns >>>>>>\")\n",
    "        logger.info(self.transformed_dataset.select_dtypes(include=[np.number]).corr())\n",
    "        logger.info(f\"<<<<<< =========================== >>>>>>\")\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i):\n",
    "                if abs(corr_matrix.iloc[i,j])> self.threshold: #absolute is to compare +ve and -ve correlated columns both with threshold.\n",
    "                    colname= corr_matrix.columns[i] #getting the name of the column\n",
    "                    col_corr.add(colname)\n",
    "        self.transformed_dataset.drop(col_corr, axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    def train_test_spliting(self):\n",
    "        train, test=train_test_split(self.transformed_dataset)\n",
    "        train.to_csv(os.path.join(self.config.root_dir,\"train.csv\"), index=False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir,\"test.csv\"), index=False)\n",
    "\n",
    "        logger.info(\"Splitted data into training and test sets\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config=ConfigurationManager()\n",
    "    data_transformation_config= config.get_data_transformation_config()\n",
    "    data_transformation=DataTransformation(config=data_transformation_config,threshold=0.87)\n",
    "    data_transformation.remove_correlated_columns()\n",
    "    data_transformation.data_standardization()\n",
    "    data_transformation.train_test_spliting()\n",
    "except Exception as e:\n",
    "    raise IrisPredictionException(e, sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irispred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
